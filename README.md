# PySpark, Confluent Kafka, Apache Drill + Docker code example
A tutorial on setting up production level data streams for PySpark, Confluent Kafka, & Drill using Docker

Data samples:

MS SQL Docker container: https://github.com/Microsoft/sql-server-samples/

PostgresSQL Docker container: https://github.com/lorint/AdventureWorks-for-Postgres

MySQL Employment data: https://github.com/datacharmer/test_db

Unstructured data (various: excel, csv, etc).

